<h1>Basic Concepts of AI</h1>


<h2>Bias</h2>
Definition: The error introduced by approximating a real-world problem, which may be complex, by a simplified model.
High Bias: Leads to underfitting, where the model is too simple to capture the underlying patterns in the data.

<h2>Variance</h2>
Definition: The error introduced by the model's sensitivity to small fluctuations in the training set.
High Variance: Leads to overfitting, where the model captures noise in the training data instead of the actual patterns.


<h2>Trade-off</h2>
Bias-Variance Trade-off: The balance between bias and variance to achieve optimal model performance. Reducing one typically increases the other.


<h2>Overfitting</h2>
Definition: When a model learns the details and noise in the training data to the extent that it negatively impacts the model's performance on new data.
Indicators: High accuracy on training data but poor accuracy on validation/test data.


<h2>Underfitting</h2>
Definition: When a model is too simple to capture the underlying structure of the data.
Indicators: Poor accuracy on both training and validation/test data.